# -*- coding: utf-8 -*-
"""redesneuronales.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MtGZApLnqLKIwZWRP6Yc2DXAoiEh6d7X
"""

# Importación de librerías necesarias
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Carga de datos desde un archivo CSV
videojuegos = pd.read_csv("Video_Games_Sales.csv")

# Eliminación de filas con valores nulos
videojuegos.dropna(inplace=True)

# Codificación de variables categóricas a valores numéricos
le_platform = LabelEncoder()
le_genre = LabelEncoder()
le_publisher = LabelEncoder()

videojuegos['Platform'] = le_platform.fit_transform(videojuegos['Platform'])
videojuegos['Genre'] = le_genre.fit_transform(videojuegos['Genre'])
videojuegos['Publisher'] = le_publisher.fit_transform(videojuegos['Publisher'])

# Definición de variables independientes (X) y dependiente (y)
X = videojuegos[['Platform', 'Year', 'Genre', 'Publisher', 'NA_Sales', 'JP_Sales', 'Other_Sales']]
y = videojuegos['EU_Sales']

# Normalización de las características (escalado de los datos)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# División de los datos en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# Importación de TensorFlow y creación del modelo de red neuronal
import tensorflow as tf
from tensorflow import keras

# Definición del modelo secuencial con capas densas (fully connected)
model = tf.keras.Sequential([
    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Primera capa oculta con 64 neuronas
    tf.keras.layers.Dense(32, activation='relu'),  # Segunda capa oculta con 32 neuronas
    tf.keras.layers.Dense(1)  # Capa de salida con una sola neurona (para regresión)
])

# Compilación del modelo con el optimizador Adam y función de pérdida MSE
model.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Entrenamiento del modelo con 20 épocas y validación interna sobre el 20% del entrenamiento
history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=1)

# Predicción sobre el conjunto de prueba
y_pred_nn = model.predict(X_test).flatten()

# Evaluación del modelo con MSE y R²
mse_nn = mean_squared_error(y_test, y_pred_nn)
r2_nn = r2_score(y_test, y_pred_nn)

# Impresión de métricas de evaluación del modelo
print(f"Error cuadrático medio (MSE) - Red Neuronal: {mse_nn}")
print(f"Coeficiente de determinación (R²) - Red Neuronal: {r2_nn}")

# Importación de matplotlib para visualización
import matplotlib.pyplot as plt

# Visualización de la pérdida (loss) durante el entrenamiento
plt.plot(history.history['loss'])  # Muestra la pérdida (error) en cada época
plt.title('Pérdida durante el entrenamiento')  # Título del gráfico
plt.xlabel('Épocas')  # Etiqueta del eje X
plt.ylabel('Loss (MSE)')  # Etiqueta del eje Y
plt.grid(True)  # Muestra una cuadrícula de fondo
plt.show()  # Muestra el gráfico

# Definición de un nuevo juego con sus características para predecir sus ventas en Europa
nuevo_juego = {
    'Platform': 'PC',
    'Year': 2025,
    'Genre': 'Action',
    'Publisher': 'Capcom',
    'NA_Sales': 15.0,
    'JP_Sales': 2.5,
    'Other_Sales': 10.3
}

# Conversión del nuevo juego a un DataFrame
nuevo_df = pd.DataFrame([nuevo_juego])

# Transformación de variables categóricas con los mismos codificadores utilizados antes
nuevo_df['Platform'] = le_platform.transform(nuevo_df['Platform'])
nuevo_df['Genre'] = le_genre.transform(nuevo_df['Genre'])
nuevo_df['Publisher'] = le_publisher.transform(nuevo_df['Publisher'])

# Normalización de las características del nuevo juego
nuevo_df_scaled = scaler.transform(nuevo_df)

# Predicción de las ventas en Europa usando el modelo entrenado
prediccion_nn = model.predict(nuevo_df_scaled)
print(f"Predicción de ventas en Europa (red neuronal): {prediccion_nn[0][0]:.2f} millones")
